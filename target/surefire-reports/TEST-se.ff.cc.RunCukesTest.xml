<?xml version="1.0" encoding="UTF-8" ?>
<testsuite tests="179" failures="0" name="se.ff.cc.RunCukesTest" time="0.869" errors="8" skipped="134">
  <properties>
    <property name="java.runtime.name" value="Java(TM) SE Runtime Environment"/>
    <property name="sun.boot.library.path" value="C:\jdk1.8.0_121\jre\bin"/>
    <property name="java.vm.version" value="25.121-b13"/>
    <property name="java.vm.vendor" value="Oracle Corporation"/>
    <property name="maven.multiModuleProjectDirectory" value="C:/Users/cwarne01/git/DLAP-test-automation"/>
    <property name="java.vendor.url" value="http://java.oracle.com/"/>
    <property name="path.separator" value=";"/>
    <property name="guice.disable.misplaced.annotation.check" value="true"/>
    <property name="java.vm.name" value="Java HotSpot(TM) 64-Bit Server VM"/>
    <property name="file.encoding.pkg" value="sun.io"/>
    <property name="user.script" value=""/>
    <property name="user.country" value="US"/>
    <property name="sun.java.launcher" value="SUN_STANDARD"/>
    <property name="sun.os.patch.level" value="Service Pack 1"/>
    <property name="java.vm.specification.name" value="Java Virtual Machine Specification"/>
    <property name="user.dir" value="C:\Users\cwarne01\git\DLAP-test-automation"/>
    <property name="java.runtime.version" value="1.8.0_121-b13"/>
    <property name="java.awt.graphicsenv" value="sun.awt.Win32GraphicsEnvironment"/>
    <property name="java.endorsed.dirs" value="C:\jdk1.8.0_121\jre\lib\endorsed"/>
    <property name="os.arch" value="amd64"/>
    <property name="java.io.tmpdir" value="C:\Users\cwarne01\AppData\Local\Temp\"/>
    <property name="line.separator" value="
"/>
    <property name="java.vm.specification.vendor" value="Oracle Corporation"/>
    <property name="user.variant" value=""/>
    <property name="os.name" value="Windows 7"/>
    <property name="classworlds.conf" value="C:/Users/cwarne01/Documents/apache-maven-3.5.4-bin/apache-maven-3.5.4/bin/m2.conf"/>
    <property name="sun.jnu.encoding" value="Cp1252"/>
    <property name="java.library.path" value="C:\jdk1.8.0_121\bin;C:\Windows\Sun\Java\bin;C:\Windows\system32;C:\Windows;Z:\bin;C:\Users\cwarne01\AppData\Local\Programs\Git\mingw64\bin;C:\Users\cwarne01\AppData\Local\Programs\Git\usr\local\bin;C:\Users\cwarne01\AppData\Local\Programs\Git\usr\bin;C:\Users\cwarne01\AppData\Local\Programs\Git\usr\bin;C:\Users\cwarne01\AppData\Local\Programs\Git\mingw64\bin;C:\Users\cwarne01\AppData\Local\Programs\Git\usr\bin;Z:\bin;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\CCM;C:\Program Files (x86)\Google\Chrome\Application;C:\Program Files (x86)\Microsoft Office\Office15;C:\Windows\system32;C:\Windows;C:\Windows\System32\Wbem;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\System32\WindowsPowerShell\v1.0;C:\Windows\CCM;C:\Users\cwarne01\.m2\bin;C:\Users\cwarne01\Documents\apache-maven-3.5.4-bin\apache-maven-3.5.4\bin;C:\jdk1.8.0_121;C:\Users\cwarne01\AppData\Local\Programs\Git\usr\bin\vendor_perl;C:\Users\cwarne01\AppData\Local\Programs\Git\usr\bin\core_perl;."/>
    <property name="maven.conf" value="C:/Users/cwarne01/Documents/apache-maven-3.5.4-bin/apache-maven-3.5.4/conf"/>
    <property name="java.specification.name" value="Java Platform API Specification"/>
    <property name="java.class.version" value="52.0"/>
    <property name="sun.management.compiler" value="HotSpot 64-Bit Tiered Compilers"/>
    <property name="os.version" value="6.1"/>
    <property name="library.jansi.path" value="C:/Users/cwarne01/Documents/apache-maven-3.5.4-bin/apache-maven-3.5.4/lib/jansi-native"/>
    <property name="user.home" value="C:\Users\cwarne01"/>
    <property name="user.timezone" value="America/New_York"/>
    <property name="java.awt.printerjob" value="sun.awt.windows.WPrinterJob"/>
    <property name="java.specification.version" value="1.8"/>
    <property name="file.encoding" value="Cp1252"/>
    <property name="user.name" value="cwarne01"/>
    <property name="java.class.path" value="C:/Users/cwarne01/Documents/apache-maven-3.5.4-bin/apache-maven-3.5.4/boot/plexus-classworlds-2.5.2.jar"/>
    <property name="java.vm.specification.version" value="1.8"/>
    <property name="sun.arch.data.model" value="64"/>
    <property name="java.home" value="C:\jdk1.8.0_121\jre"/>
    <property name="sun.java.command" value="org.codehaus.plexus.classworlds.launcher.Launcher clean install"/>
    <property name="java.specification.vendor" value="Oracle Corporation"/>
    <property name="user.language" value="en"/>
    <property name="awt.toolkit" value="sun.awt.windows.WToolkit"/>
    <property name="java.vm.info" value="mixed mode"/>
    <property name="java.version" value="1.8.0_121"/>
    <property name="java.ext.dirs" value="C:\jdk1.8.0_121\jre\lib\ext;C:\Windows\Sun\Java\lib\ext"/>
    <property name="sun.boot.class.path" value="C:\jdk1.8.0_121\jre\lib\resources.jar;C:\jdk1.8.0_121\jre\lib\rt.jar;C:\jdk1.8.0_121\jre\lib\sunrsasign.jar;C:\jdk1.8.0_121\jre\lib\jsse.jar;C:\jdk1.8.0_121\jre\lib\jce.jar;C:\jdk1.8.0_121\jre\lib\charsets.jar;C:\jdk1.8.0_121\jre\lib\jfr.jar;C:\jdk1.8.0_121\jre\classes"/>
    <property name="java.vendor" value="Oracle Corporation"/>
    <property name="maven.home" value="C:\Users\cwarne01\Documents\apache-maven-3.5.4-bin\apache-maven-3.5.4"/>
    <property name="file.separator" value="\"/>
    <property name="java.vendor.url.bug" value="http://bugreport.sun.com/bugreport/"/>
    <property name="sun.cpu.endian" value="little"/>
    <property name="sun.io.unicode.encoding" value="UnicodeLittle"/>
    <property name="sun.desktop" value="windows"/>
    <property name="sun.cpu.isalist" value="amd64"/>
  </properties>
  <testcase classname="Scenario: Test fixture of input and expected output files." name="Given an example raw file is processed all the way to the publish zone and I have an expected output xxx" time="0.006">
    <skipped/>
    <system-out>#### DLAPDEV-135,
#### CURATE_DAILY_CASH.xlsx
Feature: Data is moved from the Curate to the Publish zone and is tranformed according to onboarded workbook metadata.

  Background: I have moved a data set to Publish Zone &amp;#27;[90m# se/ff/cc/AbcControls.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Test fixture of input and expected output files." name="When I select the appropriate table via impala" time="0.007">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Test fixture of input and expected output files." name="Then the results should match the expected output xxx" time="0.007">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Test fixture of input and expected output files." name="Scenario: Test fixture of input and expected output files." time="0.007">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Test fixture of input and expected output files." name="Scenario: Test fixture of input and expected output files." time="0.007"/>
  <testcase classname="Scenario: Rows in the Publish zone data set should have columns per the workbook." name="Given a data set in the RW zone and its counterpart in the curate zone" time="0.002">
    <skipped/>
    <system-out>
  Scenario: Test fixture of input and expected output files.                                                 &amp;#27;[90m# se/ff/cc/AbcControls.feature:9&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33man example raw file is processed all the way to the publish zone and I have an expected output xxx&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI select the appropriate table via impala&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mthe results should match the expected output xxx&amp;#27;[0m

  Background: I have moved a data set to Publish Zone &amp;#27;[90m# se/ff/cc/AbcControls.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should have columns per the workbook." name="When I query Cloudera Naviator for the data set&apos;s onboarded workbook metadata" time="0.002">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should have columns per the workbook." name="Then fields flagged for encrption in the metadata should be actually encrypted in the curate zone" time="0.002">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should have columns per the workbook." name="Scenario: Rows in the Publish zone data set should have columns per the workbook." time="0.002">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should have columns per the workbook." name="Scenario: Rows in the Publish zone data set should have columns per the workbook." time="0.002"/>
  <testcase classname="Scenario: Rows in the Publish zone data set should ." name="Given a data set in the RAW zne and its counterpart in the curate zone" time="0.001">
    <skipped/>
    <system-out>
  Scenario: Rows in the Publish zone data set should have columns per the workbook.                   &amp;#27;[90m# se/ff/cc/AbcControls.feature:18&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33ma data set in the RW zone and its counterpart in the curate zone&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Cloudera Naviator for the data set&apos;s onboarded workbook metadata&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mfields flagged for encrption in the metadata should be actually encrypted in the curate zone&amp;#27;[0m

  Background: I have moved a data set to Publish Zone &amp;#27;[90m# se/ff/cc/AbcControls.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should ." name="When I query Cloudera Naviator for the data set&apos;s onboarded workbook metadata" time="0.002">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should ." name="Then fields flagged for encrption in the metadata should be actually encrypted in the curate zone" time="0.002">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should ." name="Scenario: Rows in the Publish zone data set should ." time="0.002">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should ." name="Scenario: Rows in the Publish zone data set should ." time="0.002"/>
  <testcase classname="Scenario: Curate workbook schema validation." name="Given I have parsed a workbook" time="0"/>
  <testcase classname="Scenario: Curate workbook schema validation." name="When I query Cloudera Navigator for that workbook&apos;s metadata" time="0.017">
    <error message="Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect" type="org.apache.http.conn.HttpHostConnectException">org.apache.http.conn.HttpHostConnectException: Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:159)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
	at ✽.When I query Cloudera Navigator for that workbook&apos;s metadata(se/ff/cc/AbcControls.feature:32)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:339)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at cucumber.runtime.Utils$1.call(Utils.java:37)
	at cucumber.runtime.Timeout.timeout(Timeout.java:13)
	at cucumber.runtime.Utils.invoke(Utils.java:31)
	at cucumber.runtime.java.JavaStepDefinition.execute(JavaStepDefinition.java:38)
	at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)
	at cucumber.runtime.Runtime.runStep(Runtime.java:299)
	at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)
	at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)
	at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)
	at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:91)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:93)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:37)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.api.junit.Cucumber.run(Cucumber.java:98)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
</error>
    <system-out>com.prft.cif.rest.NavigatorRestClient@1da6ee17
2018-11-06 17:39:10 DEBUG RequestAddCookies:123 - CookieSpec selected: default
2018-11-06 17:39:10 DEBUG RequestAuthCache:77 - Auth cache not set in the context
2018-11-06 17:39:10 DEBUG PoolingHttpClientConnectionManager:265 - Connection request: [route: {s}-&gt;https://bclmp01vr.bcbsma.com:7187][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
2018-11-06 17:39:10 DEBUG PoolingHttpClientConnectionManager:309 - Connection leased: [id: 0][route: {s}-&gt;https://bclmp01vr.bcbsma.com:7187][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
2018-11-06 17:39:10 DEBUG MainClientExec:235 - Opening connection {s}-&gt;https://bclmp01vr.bcbsma.com:7187
2018-11-06 17:39:10 DEBUG DefaultHttpClientConnectionOperator:139 - Connecting to bclmp01vr.bcbsma.com/10.15.126.18:7187
2018-11-06 17:39:10 DEBUG SSLConnectionSocketFactory:337 - Connecting socket to bclmp01vr.bcbsma.com/10.15.126.18:7187 with timeout 0
2018-11-06 17:39:31 DEBUG DefaultManagedHttpClientConnection:96 - http-outgoing-0: Shutdown connection
2018-11-06 17:39:31 DEBUG MainClientExec:129 - Connection discarded
2018-11-06 17:39:31 DEBUG PoolingHttpClientConnectionManager:348 - Connection released: [id: 0][route: {s}-&gt;https://bclmp01vr.bcbsma.com:7187][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
</system-out>
  </testcase>
  <testcase classname="Scenario: Curate workbook schema validation." name="Scenario: Curate workbook schema validation." time="0.024">
    <error message="Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect" type="org.apache.http.conn.HttpHostConnectException">org.apache.http.conn.HttpHostConnectException: Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:159)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
	at ✽.When I query Cloudera Navigator for that workbook&apos;s metadata(se/ff/cc/AbcControls.feature:32)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:339)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at cucumber.runtime.Utils$1.call(Utils.java:37)
	at cucumber.runtime.Timeout.timeout(Timeout.java:13)
	at cucumber.runtime.Utils.invoke(Utils.java:31)
	at cucumber.runtime.java.JavaStepDefinition.execute(JavaStepDefinition.java:38)
	at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)
	at cucumber.runtime.Runtime.runStep(Runtime.java:299)
	at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)
	at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)
	at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)
	at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:91)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:93)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:37)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.api.junit.Cucumber.run(Cucumber.java:98)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
</error>
  </testcase>
  <testcase classname="Scenario: Curate workbook schema validation." name="Then I should see Hive columns in the appropriate DB" time="0.024">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Curate workbook schema validation." name="Scenario: Curate workbook schema validation." time="0.024">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Data from the RAW zone should be completely ingested to the curate zone according to the metadata provided by the workbook." name="Given a data set in the RAW zone and its counterpart in the curate zone" time="0"/>
  <testcase classname="Scenario: Data from the RAW zone should be completely ingested to the curate zone according to the metadata provided by the workbook." name="When I query Cloudera Navigator for the data set&apos;s onboarded workbook metadata" time="0">
    <error message="Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect" type="org.apache.http.conn.HttpHostConnectException">org.apache.http.conn.HttpHostConnectException: Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:159)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.CurateStepDefs.something_is_done(CurateStepDefs.java:65)
	at ✽.When I query Cloudera Navigator for the data set&apos;s onboarded workbook metadata(se/ff/cc/Curate.feature:10)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:339)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.CurateStepDefs.something_is_done(CurateStepDefs.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at cucumber.runtime.Utils$1.call(Utils.java:37)
	at cucumber.runtime.Timeout.timeout(Timeout.java:13)
	at cucumber.runtime.Utils.invoke(Utils.java:31)
	at cucumber.runtime.java.JavaStepDefinition.execute(JavaStepDefinition.java:38)
	at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)
	at cucumber.runtime.Runtime.runStep(Runtime.java:299)
	at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)
	at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)
	at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)
	at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:91)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:93)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:37)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.api.junit.Cucumber.run(Cucumber.java:98)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
</error>
    <system-out>2018-11-06 17:39:32 DEBUG RequestAddCookies:123 - CookieSpec selected: default
2018-11-06 17:39:32 DEBUG RequestAuthCache:77 - Auth cache not set in the context
2018-11-06 17:39:32 DEBUG PoolingHttpClientConnectionManager:265 - Connection request: [route: {s}-&gt;https://bclmp01vr.bcbsma.com:7187][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
2018-11-06 17:39:32 DEBUG PoolingHttpClientConnectionManager:309 - Connection leased: [id: 1][route: {s}-&gt;https://bclmp01vr.bcbsma.com:7187][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
2018-11-06 17:39:32 DEBUG MainClientExec:235 - Opening connection {s}-&gt;https://bclmp01vr.bcbsma.com:7187
2018-11-06 17:39:32 DEBUG DefaultHttpClientConnectionOperator:139 - Connecting to bclmp01vr.bcbsma.com/10.15.126.18:7187
2018-11-06 17:39:32 DEBUG SSLConnectionSocketFactory:337 - Connecting socket to bclmp01vr.bcbsma.com/10.15.126.18:7187 with timeout 0
2018-11-06 17:39:53 DEBUG DefaultManagedHttpClientConnection:96 - http-outgoing-1: Shutdown connection
2018-11-06 17:39:53 DEBUG MainClientExec:129 - Connection discarded
2018-11-06 17:39:53 DEBUG PoolingHttpClientConnectionManager:348 - Connection released: [id: 1][route: {s}-&gt;https://bclmp01vr.bcbsma.com:7187][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
</system-out>
  </testcase>
  <testcase classname="Scenario: Data from the RAW zone should be completely ingested to the curate zone according to the metadata provided by the workbook." name="Scenario: Data from the RAW zone should be completely ingested to the curate zone according to the metadata provided by the workbook." time="0.001">
    <error message="Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect" type="org.apache.http.conn.HttpHostConnectException">org.apache.http.conn.HttpHostConnectException: Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:159)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.CurateStepDefs.something_is_done(CurateStepDefs.java:65)
	at ✽.When I query Cloudera Navigator for the data set&apos;s onboarded workbook metadata(se/ff/cc/Curate.feature:10)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:339)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.CurateStepDefs.something_is_done(CurateStepDefs.java:65)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at cucumber.runtime.Utils$1.call(Utils.java:37)
	at cucumber.runtime.Timeout.timeout(Timeout.java:13)
	at cucumber.runtime.Utils.invoke(Utils.java:31)
	at cucumber.runtime.java.JavaStepDefinition.execute(JavaStepDefinition.java:38)
	at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)
	at cucumber.runtime.Runtime.runStep(Runtime.java:299)
	at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)
	at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)
	at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)
	at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:91)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:93)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:37)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.api.junit.Cucumber.run(Cucumber.java:98)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
</error>
  </testcase>
  <testcase classname="Scenario: Data from the RAW zone should be completely ingested to the curate zone according to the metadata provided by the workbook." name="Then fields flagged for encryption in the metadata should be actually encrypted in the curate zone" time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Fields flagged for encryption by the workbook should be encrypted in the target zone." name="Given a data set in the RAW zne and its counterpart in the curate zone" time="0.002">
    <skipped/>
    <system-out>
  Scenario: Data from the RAW zone should be completely ingested to the curate zone according to the metadata provided by the workbook. &amp;#27;[90m# se/ff/cc/Curate.feature:8&amp;#27;[0m
    &amp;#27;[32mGiven &amp;#27;[0m&amp;#27;[32ma data set in the RAW zone and its counterpart in the curate zone&amp;#27;[0m                                                             &amp;#27;[90m# CurateStepDefs.some_start_condition()&amp;#27;[0m
    &amp;#27;[31mWhen &amp;#27;[0m&amp;#27;[31mI query Cloudera Navigator for the data set&apos;s onboarded workbook metadata&amp;#27;[0m                                                      &amp;#27;[90m# CurateStepDefs.something_is_done()&amp;#27;[0m
      &amp;#27;[31morg.apache.http.conn.HttpHostConnectException: Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect
      	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:159)
      	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
      	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
      	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
      	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
      	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
      	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
      	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
      	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
      	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
      	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
      	at se.ff.cc.CurateStepDefs.something_is_done(CurateStepDefs.java:65)
      	at ?.When I query Cloudera Navigator for the data set&apos;s onboarded workbook metadata(se/ff/cc/Curate.feature:10)
      Caused by: java.net.ConnectException: Connection timed out: connect
      	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
      	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
      	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
      	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
      	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
      	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
      	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
      	at java.net.Socket.connect(Socket.java:589)
      	at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:339)
      	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
      	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
      	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
      	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
      	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
      	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
      	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
      	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
      	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
      	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
      	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
      	at se.ff.cc.CurateStepDefs.something_is_done(CurateStepDefs.java:65)
      	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
      	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
      	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
      	at java.lang.reflect.Method.invoke(Method.java:498)
      	at cucumber.runtime.Utils$1.call(Utils.java:37)
      	at cucumber.runtime.Timeout.timeout(Timeout.java:13)
      	at cucumber.runtime.Utils.invoke(Utils.java:31)
      	at cucumber.runtime.java.JavaStepDefinition.execute(JavaStepDefinition.java:38)
      	at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)
      	at cucumber.runtime.Runtime.runStep(Runtime.java:299)
      	at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)
      	at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)
      	at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)
      	at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:91)
      	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)
      	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)
      	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
      	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
      	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
      	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
      	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
      	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
      	at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)
      	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:93)
      	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:37)
      	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
      	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
      	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
      	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
      	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
      	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
      	at cucumber.api.junit.Cucumber.run(Cucumber.java:98)
      	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
      	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
      	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
      	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
      	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
      	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
      	at java.lang.reflect.Method.invoke(Method.java:498)
      	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
      	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
      	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
      	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
      	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
      &amp;#27;[0m
    &amp;#27;[36mThen &amp;#27;[0m&amp;#27;[36mfields flagged for encryption in the metadata should be actually encrypted in the curate zone&amp;#27;[0m                                  &amp;#27;[90m# CurateStepDefs.something_should_happen()&amp;#27;[0m

  Background: I have ingested the data set &quot;data set name or xlsx&quot; &amp;#27;[90m# se/ff/cc/Curate.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Fields flagged for encryption by the workbook should be encrypted in the target zone." name="When I select rows with columns flagged for encryption" time="0.002">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Fields flagged for encryption by the workbook should be encrypted in the target zone." name="Then fields flagged for encryption in the metdata should be actually encrypted in the curate zone" time="0.002">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Fields flagged for encryption by the workbook should be encrypted in the target zone." name="Scenario: Fields flagged for encryption by the workbook should be encrypted in the target zone." time="0.002">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Fields flagged for encryption by the workbook should be encrypted in the target zone." name="Scenario: Fields flagged for encryption by the workbook should be encrypted in the target zone." time="0.002"/>
  <testcase classname="Scenario: The record count in the curate zone data set should match the record count in the RAW file." name="Given a data set in the RAW zne and its counterpart in the curate zone" time="0">
    <skipped/>
    <system-out>
  Scenario: Fields flagged for encryption by the workbook should be encrypted in the target zone.     &amp;#27;[90m# se/ff/cc/Curate.feature:13&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33ma data set in the RAW zne and its counterpart in the curate zone&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI select rows with columns flagged for encryption&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mfields flagged for encryption in the metdata should be actually encrypted in the curate zone&amp;#27;[0m

  Background: I have ingested the data set &quot;data set name or xlsx&quot; &amp;#27;[90m# se/ff/cc/Curate.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: The record count in the curate zone data set should match the record count in the RAW file." name="When I query Hive for the record count" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: The record count in the curate zone data set should match the record count in the RAW file." name="Then the record count should match the record count of the file in the RAW zone" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: The record count in the curate zone data set should match the record count in the RAW file." name="Scenario: The record count in the curate zone data set should match the record count in the RAW file." time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: The record count in the curate zone data set should match the record count in the RAW file." name="Scenario: The record count in the curate zone data set should match the record count in the RAW file." time="0"/>
  <testcase classname="Scenario: Rows in the Curate zone data set should have columns per the workbook." name="Given a data set in the RW zone and its counterpart in the curate zone" time="0">
    <skipped/>
    <system-out>
  ###   Row counting is problematic - design review needed
  Scenario: The record count in the curate zone data set should match the record count in the RAW file. &amp;#27;[90m# se/ff/cc/Curate.feature:19&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33ma data set in the RAW zne and its counterpart in the curate zone&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive for the record count&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mthe record count should match the record count of the file in the RAW zone&amp;#27;[0m

  Background: I have ingested the data set &quot;data set name or xlsx&quot; &amp;#27;[90m# se/ff/cc/Curate.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Rows in the Curate zone data set should have columns per the workbook." name="When I query Cloudera Naviator for the data set&apos;s onboarded workbook metadata" time="0.004">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Curate zone data set should have columns per the workbook." name="Then fields flagged for encrption in the metadata should be actually encrypted in the curate zone" time="0.004">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Curate zone data set should have columns per the workbook." name="Scenario: Rows in the Curate zone data set should have columns per the workbook." time="0.004">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Curate zone data set should have columns per the workbook." name="Scenario: Rows in the Curate zone data set should have columns per the workbook." time="0.004"/>
  <testcase classname="Scenario: Rows in the Curate zone data set should be transformed correctly." name="Given a data set in the RAW zne and its counterpart in the curate zone" time="0">
    <skipped/>
    <system-out>
  Scenario: Rows in the Curate zone data set should have columns per the workbook.                    &amp;#27;[90m# se/ff/cc/Curate.feature:25&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33ma data set in the RW zone and its counterpart in the curate zone&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Cloudera Naviator for the data set&apos;s onboarded workbook metadata&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mfields flagged for encrption in the metadata should be actually encrypted in the curate zone&amp;#27;[0m

  Background: I have ingested the data set &quot;data set name or xlsx&quot; &amp;#27;[90m# se/ff/cc/Curate.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Rows in the Curate zone data set should be transformed correctly." name="When I query Hive for data rows containing columns that required transform" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Curate zone data set should be transformed correctly." name="Then the data in the row/column should be tranformed correctly" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Curate zone data set should be transformed correctly." name="Scenario: Rows in the Curate zone data set should be transformed correctly." time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Curate zone data set should be transformed correctly." name="Scenario: Rows in the Curate zone data set should be transformed correctly." time="0"/>
  <testcase classname="Scenario: RAW zone file transfer." name="Given I have parsed a workbook" time="0"/>
  <testcase classname="Scenario: RAW zone file transfer." name="And I have a datafile" time="0.002">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: RAW zone file transfer." name="When I query Cloudera Navigator for that dataset&apos;s metadata" time="0.003">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: RAW zone file transfer." name="Then I should see the RAW file in the appropriate HDFS folder" time="0.003">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: RAW zone file transfer." name="Scenario: RAW zone file transfer." time="0.003">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: RAW zone file transfer." name="Scenario: RAW zone file transfer." time="0.003"/>
  <testcase classname="Scenario: Bad data files result in an error being logged." name="Given an bad example raw file is processed all the way to the publish zone and I have an expected output xxx" time="0.004">
    <skipped/>
    <system-out>
  Scenario: RAW zone file transfer.                               &amp;#27;[90m# se/ff/cc/Curate.feature:39&amp;#27;[0m
    &amp;#27;[32mGiven &amp;#27;[0m&amp;#27;[32mI have parsed a workbook&amp;#27;[0m                                &amp;#27;[90m# WorkbookStepDefs.some_start_condition()&amp;#27;[0m
    &amp;#27;[33mAnd &amp;#27;[0m&amp;#27;[33mI have a datafile&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Cloudera Navigator for that dataset&apos;s metadata&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mI should see the RAW file in the appropriate HDFS folder&amp;#27;[0m

  Background: I have ingested the data set &quot;data set name or xlsx&quot; &amp;#27;[90m# se/ff/cc/Curate.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Bad data files result in an error being logged." name="When I query Hive for the record count" time="0.004">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Bad data files result in an error being logged." name="Then the record count should match the record count of the file in the RAW zone" time="0.004">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Bad data files result in an error being logged." name="Scenario: Bad data files result in an error being logged." time="0.004">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Bad data files result in an error being logged." name="Scenario: Bad data files result in an error being logged." time="0.005"/>
  <testcase classname="Scenario: Incomplete data files result in an error being logged." name="Given an bad example raw file is processed all the way to the publish zone and I have an expected output xxx" time="0.001">
    <skipped/>
    <system-out>
  Scenario: Bad data files result in an error being logged.                                                      &amp;#27;[90m# se/ff/cc/Curate.feature:45&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33man bad example raw file is processed all the way to the publish zone and I have an expected output xxx&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive for the record count&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mthe record count should match the record count of the file in the RAW zone&amp;#27;[0m

  Background: I have ingested the data set &quot;data set name or xlsx&quot; &amp;#27;[90m# se/ff/cc/Curate.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Incomplete data files result in an error being logged." name="When I query Hive for the record count" time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Incomplete data files result in an error being logged." name="Then the record count should match the record count of the file in the RAW zone" time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Incomplete data files result in an error being logged." name="Scenario: Incomplete data files result in an error being logged." time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Incomplete data files result in an error being logged." name="Scenario: Incomplete data files result in an error being logged." time="0.001"/>
  <testcase classname="Scenario: Invalid data file formats result in an error being logged." name="Given a data file with an invalid file type" time="0">
    <skipped/>
    <system-out>
  Scenario: Incomplete data files result in an error being logged.                                               &amp;#27;[90m# se/ff/cc/Curate.feature:50&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33man bad example raw file is processed all the way to the publish zone and I have an expected output xxx&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive for the record count&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mthe record count should match the record count of the file in the RAW zone&amp;#27;[0m

  Background: I have ingested the data set &quot;data set name or xlsx&quot; &amp;#27;[90m# se/ff/cc/Curate.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Invalid data file formats result in an error being logged." name="When I attempt to ingest the file" time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Invalid data file formats result in an error being logged." name="Then an error should be thrown for the file type" time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Invalid data file formats result in an error being logged." name="Scenario: Invalid data file formats result in an error being logged." time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Invalid data file formats result in an error being logged." name="Scenario: Invalid data file formats result in an error being logged." time="0.001"/>
  <testcase classname="Scenario: Field-level expression/transformation validation." name="Given I have parsed a workbook and the data has been ingested to the target zone." time="0.009">
    <skipped/>
    <system-out>
  Scenario: Invalid data file formats result in an error being logged. &amp;#27;[90m# se/ff/cc/Curate.feature:55&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33ma data file with an invalid file type&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI attempt to ingest the file&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33man error should be thrown for the file type&amp;#27;[0m

  Background: I have ingested the data set &quot;data set name or xlsx&quot; &amp;#27;[90m# se/ff/cc/Curate.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Field-level expression/transformation validation." name="When I query Hive for a field that has been transformed." time="0.009">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Field-level expression/transformation validation." name="Then I should see the correct tranformed data in the query result." time="0.009">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Field-level expression/transformation validation." name="Scenario: Field-level expression/transformation validation." time="0.009">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Field-level expression/transformation validation." name="Scenario: Field-level expression/transformation validation." time="0.009"/>
  <testcase classname="Scenario: Publish scheduling." name="Given an example raw file is processed all the way to the publish zone and I have an expected output xxx" time="0">
    <skipped/>
    <system-out>
  Scenario: Field-level expression/transformation validation.                         &amp;#27;[90m# se/ff/cc/Curate.feature:60&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33mI have parsed a workbook and the data has been ingested to the target zone.&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive for a field that has been transformed.&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mI should see the correct tranformed data in the query result.&amp;#27;[0m
#### DLAPDEV-135,
#### CURATE_DAILY_CASH.xlsx
Feature: Data is moved from the Curate to the Publish zone and is transformed according to onboarded workbook metadata.

  Background: I have moved a data set to Publish Zone &amp;#27;[90m# se/ff/cc/Publish.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Publish scheduling." name="When I select the appropriate table via impala" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Publish scheduling." name="Then the results should match the expected output xxx" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Publish scheduling." name="Scenario: Publish scheduling." time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Publish scheduling." name="Scenario: Publish scheduling." time="0"/>
  <testcase classname="Scenario: Rows in the Publish zone data set should have columns per the workbook." name="Given a data set in the RW zone and its counterpart in the curate zone" time="0.029">
    <skipped/>
    <system-out>
  Scenario: Publish scheduling.                                                                              &amp;#27;[90m# se/ff/cc/Publish.feature:10&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33man example raw file is processed all the way to the publish zone and I have an expected output xxx&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI select the appropriate table via impala&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mthe results should match the expected output xxx&amp;#27;[0m

  Background: I have moved a data set to Publish Zone &amp;#27;[90m# se/ff/cc/Publish.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should have columns per the workbook." name="When I query Cloudera Naviator for the data set&apos;s onboarded workbook metadata" time="0.029">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should have columns per the workbook." name="Then fields flagged for encrption in the metadata should be actually encrypted in the curate zone" time="0.029">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should have columns per the workbook." name="Scenario: Rows in the Publish zone data set should have columns per the workbook." time="0.029">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should have columns per the workbook." name="Scenario: Rows in the Publish zone data set should have columns per the workbook." time="0.029"/>
  <testcase classname="Scenario: Rows in the Publish zone data set should have their columns transformed correctly." name="Given an ingested data set with expected output xxx" time="0.003">
    <skipped/>
    <system-out>
  ## Duplicates workbooks validation
  Scenario: Rows in the Publish zone data set should have columns per the workbook.                   &amp;#27;[90m# se/ff/cc/Publish.feature:17&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33ma data set in the RW zone and its counterpart in the curate zone&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Cloudera Naviator for the data set&apos;s onboarded workbook metadata&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mfields flagged for encrption in the metadata should be actually encrypted in the curate zone&amp;#27;[0m

  Background: I have moved a data set to Publish Zone &amp;#27;[90m# se/ff/cc/Publish.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should have their columns transformed correctly." name="When I query Hive/Impala for each row" time="0.003">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should have their columns transformed correctly." name="Then the row matches our expected output" time="0.003">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should have their columns transformed correctly." name="Scenario: Rows in the Publish zone data set should have their columns transformed correctly." time="0.003">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Rows in the Publish zone data set should have their columns transformed correctly." name="Scenario: Rows in the Publish zone data set should have their columns transformed correctly." time="0.003"/>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS." name="Given a data set in the RAW zne and its counterpart in the curate zone" time="0">
    <skipped/>
    <system-out>
  Scenario: Rows in the Publish zone data set should have their columns transformed correctly. &amp;#27;[90m# se/ff/cc/Publish.feature:23&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33man ingested data set with expected output xxx&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive/Impala for each row&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mthe row matches our expected output&amp;#27;[0m

  Background: I have moved a data set to Publish Zone &amp;#27;[90m# se/ff/cc/Publish.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS." name="When I query Cloudera Naviator for the data set&apos;s onboarded workbook metadata" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS." name="Then fields flagged for encrption in the metadata should be actually encrypted in the curate zone&apos;" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS." name="Scenario: For publish, a data file should show up in the publish folder in HDFS." time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS." name="Scenario: For publish, a data file should show up in the publish folder in HDFS." time="0"/>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS as the correct file type." name="Given a data set in the RAW zne and its counterpart in the curate zone" time="0.008">
    <skipped/>
    <system-out>
  Scenario: For publish, a data file should show up in the publish folder in HDFS.                     &amp;#27;[90m# se/ff/cc/Publish.feature:29&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33ma data set in the RAW zne and its counterpart in the curate zone&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Cloudera Naviator for the data set&apos;s onboarded workbook metadata&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mfields flagged for encrption in the metadata should be actually encrypted in the curate zone&apos;&amp;#27;[0m

  Background: I have moved a data set to Publish Zone &amp;#27;[90m# se/ff/cc/Publish.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS as the correct file type." name="When I query Cloudera Naviator for the data set&apos;s onboarded workbook metadata" time="0.008">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS as the correct file type." name="Then fields flagged for encrption in the metadata should be actually encrypted in the curate zone&apos;" time="0.008">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS as the correct file type." name="Scenario: For publish, a data file should show up in the publish folder in HDFS as the correct file type." time="0.008">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS as the correct file type." name="Scenario: For publish, a data file should show up in the publish folder in HDFS as the correct file type." time="0.008"/>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct partitions." name="Given a data set in the RAW zne and its counterpart in the curate zone" time="0">
    <skipped/>
    <system-out>
  Scenario: For publish, a data file should show up in the publish folder in HDFS as the correct file type. &amp;#27;[90m# se/ff/cc/Publish.feature:34&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33ma data set in the RAW zne and its counterpart in the curate zone&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Cloudera Naviator for the data set&apos;s onboarded workbook metadata&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mfields flagged for encrption in the metadata should be actually encrypted in the curate zone&apos;&amp;#27;[0m

  Background: I have moved a data set to Publish Zone &amp;#27;[90m# se/ff/cc/Publish.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct partitions." name="When I query Cloudera Naviator for the data set&apos;s onboarded workbook metadata" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct partitions." name="Then fields flagged for encrption in the metadata should be actually encrypted in the curate zone&apos;" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct partitions." name="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct partitions." time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct partitions." name="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct partitions." time="0.004"/>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS." name="Given a data set in the RAW zne and its counterpart in the curate zone" time="0">
    <skipped/>
    <system-out>
  Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct partitions. &amp;#27;[90m# se/ff/cc/Publish.feature:39&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33ma data set in the RAW zne and its counterpart in the curate zone&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Cloudera Naviator for the data set&apos;s onboarded workbook metadata&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mfields flagged for encrption in the metadata should be actually encrypted in the curate zone&apos;&amp;#27;[0m

  Background: I have moved a data set to Publish Zone &amp;#27;[90m# se/ff/cc/Publish.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS." name="When I query Cloudera Naviator for the data set&apos;s onboarded workbook metadata" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS." name="Then fields flagged for encrption in the metadata should be actually encrypted in the curate zone&apos;" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS." name="Scenario: For publish, a data file should show up in the publish folder in HDFS." time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS." name="Scenario: For publish, a data file should show up in the publish folder in HDFS." time="0"/>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct compression   --  see if this needs tested  - parquet in GZIP format." name="Given a data set in the RAW zne and its counterpart in the curate zone" time="0">
    <skipped/>
    <system-out>
  Scenario: For publish, a data file should show up in the publish folder in HDFS.                     &amp;#27;[90m# se/ff/cc/Publish.feature:44&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33ma data set in the RAW zne and its counterpart in the curate zone&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Cloudera Naviator for the data set&apos;s onboarded workbook metadata&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mfields flagged for encrption in the metadata should be actually encrypted in the curate zone&apos;&amp;#27;[0m

  Background: I have moved a data set to Publish Zone &amp;#27;[90m# se/ff/cc/Publish.feature:6&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct compression   --  see if this needs tested  - parquet in GZIP format." name="When I query Cloudera Naviator for the data set&apos;s onboarded workbook metadata" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct compression   --  see if this needs tested  - parquet in GZIP format." name="Then fields flagged for encrption in the metadata should be actually encrypted in the curate zone&apos;" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct compression   --  see if this needs tested  - parquet in GZIP format." name="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct compression   --  see if this needs tested  - parquet in GZIP format." time="0.026">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct compression   --  see if this needs tested  - parquet in GZIP format." name="Scenario: For publish, a data file should show up in the publish folder in HDFS with the correct compression   --  see if this needs tested  - parquet in GZIP format." time="0.026"/>
  <testcase classname="Scenario: Curate workbook schema validation." name="Given I have parsed a workbook" time="0"/>
  <testcase classname="Scenario: Curate workbook schema validation." name="When I query Cloudera Navigator for that workbook&apos;s metadata" time="0.007">
    <error message="Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect" type="org.apache.http.conn.HttpHostConnectException">org.apache.http.conn.HttpHostConnectException: Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:159)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
	at ✽.When I query Cloudera Navigator for that workbook&apos;s metadata(se/ff/cc/Publish.feature:57)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:339)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at cucumber.runtime.Utils$1.call(Utils.java:37)
	at cucumber.runtime.Timeout.timeout(Timeout.java:13)
	at cucumber.runtime.Utils.invoke(Utils.java:31)
	at cucumber.runtime.java.JavaStepDefinition.execute(JavaStepDefinition.java:38)
	at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)
	at cucumber.runtime.Runtime.runStep(Runtime.java:299)
	at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)
	at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)
	at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)
	at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:91)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:93)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:37)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.api.junit.Cucumber.run(Cucumber.java:98)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
</error>
    <system-out>com.prft.cif.rest.NavigatorRestClient@a137d7a
2018-11-06 17:40:00 DEBUG RequestAddCookies:123 - CookieSpec selected: default
2018-11-06 17:40:00 DEBUG RequestAuthCache:77 - Auth cache not set in the context
2018-11-06 17:40:00 DEBUG PoolingHttpClientConnectionManager:265 - Connection request: [route: {s}-&gt;https://bclmp01vr.bcbsma.com:7187][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
2018-11-06 17:40:00 DEBUG PoolingHttpClientConnectionManager:309 - Connection leased: [id: 2][route: {s}-&gt;https://bclmp01vr.bcbsma.com:7187][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
2018-11-06 17:40:00 DEBUG MainClientExec:235 - Opening connection {s}-&gt;https://bclmp01vr.bcbsma.com:7187
2018-11-06 17:40:00 DEBUG DefaultHttpClientConnectionOperator:139 - Connecting to bclmp01vr.bcbsma.com/10.15.126.18:7187
2018-11-06 17:40:00 DEBUG SSLConnectionSocketFactory:337 - Connecting socket to bclmp01vr.bcbsma.com/10.15.126.18:7187 with timeout 0
2018-11-06 17:40:21 DEBUG DefaultManagedHttpClientConnection:96 - http-outgoing-2: Shutdown connection
2018-11-06 17:40:21 DEBUG MainClientExec:129 - Connection discarded
2018-11-06 17:40:21 DEBUG PoolingHttpClientConnectionManager:348 - Connection released: [id: 2][route: {s}-&gt;https://bclmp01vr.bcbsma.com:7187][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
</system-out>
  </testcase>
  <testcase classname="Scenario: Curate workbook schema validation." name="Scenario: Curate workbook schema validation." time="0.008">
    <error message="Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect" type="org.apache.http.conn.HttpHostConnectException">org.apache.http.conn.HttpHostConnectException: Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:159)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
	at ✽.When I query Cloudera Navigator for that workbook&apos;s metadata(se/ff/cc/Publish.feature:57)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:339)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at cucumber.runtime.Utils$1.call(Utils.java:37)
	at cucumber.runtime.Timeout.timeout(Timeout.java:13)
	at cucumber.runtime.Utils.invoke(Utils.java:31)
	at cucumber.runtime.java.JavaStepDefinition.execute(JavaStepDefinition.java:38)
	at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)
	at cucumber.runtime.Runtime.runStep(Runtime.java:299)
	at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)
	at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)
	at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)
	at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:91)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:93)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:37)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.api.junit.Cucumber.run(Cucumber.java:98)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
</error>
  </testcase>
  <testcase classname="Scenario: Curate workbook schema validation." name="Then I should see Hive columns in the appropriate DB" time="0.03">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Curate workbook schema validation." name="Scenario: Curate workbook schema validation." time="0.03">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 1 record are all loaded." name="Given Day 1 RME incremental files are ingested" time="0">
    <skipped/>
    <system-out>
  Scenario: Curate workbook schema validation.                   &amp;#27;[90m# se/ff/cc/Publish.feature:55&amp;#27;[0m
    &amp;#27;[32mGiven &amp;#27;[0m&amp;#27;[32mI have parsed a workbook&amp;#27;[0m                               &amp;#27;[90m# WorkbookStepDefs.some_start_condition()&amp;#27;[0m
    &amp;#27;[31mWhen &amp;#27;[0m&amp;#27;[31mI query Cloudera Navigator for that workbook&apos;s metadata&amp;#27;[0m &amp;#27;[90m# WorkbookStepDefs.something_is_done()&amp;#27;[0m
      &amp;#27;[31morg.apache.http.conn.HttpHostConnectException: Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect
      	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:159)
      	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
      	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
      	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
      	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
      	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
      	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
      	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
      	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
      	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
      	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
      	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
      	at ?.When I query Cloudera Navigator for that workbook&apos;s metadata(se/ff/cc/Publish.feature:57)
      Caused by: java.net.ConnectException: Connection timed out: connect
      	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
      	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
      	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
      	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
      	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
      	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
      	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
      	at java.net.Socket.connect(Socket.java:589)
      	at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:339)
      	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
      	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
      	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
      	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
      	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
      	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
      	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
      	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
      	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
      	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
      	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
      	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
      	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
      	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
      	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
      	at java.lang.reflect.Method.invoke(Method.java:498)
      	at cucumber.runtime.Utils$1.call(Utils.java:37)
      	at cucumber.runtime.Timeout.timeout(Timeout.java:13)
      	at cucumber.runtime.Utils.invoke(Utils.java:31)
      	at cucumber.runtime.java.JavaStepDefinition.execute(JavaStepDefinition.java:38)
      	at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)
      	at cucumber.runtime.Runtime.runStep(Runtime.java:299)
      	at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)
      	at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)
      	at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)
      	at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:91)
      	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)
      	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)
      	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
      	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
      	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
      	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
      	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
      	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
      	at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)
      	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:93)
      	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:37)
      	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
      	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
      	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
      	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
      	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
      	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
      	at cucumber.api.junit.Cucumber.run(Cucumber.java:98)
      	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
      	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
      	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
      	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
      	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
      	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
      	at java.lang.reflect.Method.invoke(Method.java:498)
      	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
      	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
      	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
      	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
      	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
      &amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mI should see Hive columns in the appropriate DB&amp;#27;[0m
Feature: f1
Feature: f2
Feature: Incremental file loading incremental testing of scd flag update for views

  ## Count of columns should be # + 4 (timestamp, cflag dflag, feeddate) for scd table
  ## verify that timestamps get updated as they want feed date - date that the extract came and date that something actually changed
  ## RME_Incremental_Test_Cases_2nd_Iteration.xlsx
  Background: Full file has been uploaded with action types as null &amp;#27;[90m# se/ff/cc/incremental.feature:8&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Day 1 record are all loaded." name="When I query Hive SCD table" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 1 record are all loaded." name="Then the record count should be correct" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 1 record are all loaded." name="Scenario: Day 1 record are all loaded." time="0.003">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 1 record are all loaded." name="Scenario: Day 1 record are all loaded." time="0.044"/>
  <testcase classname="Scenario: Day 1 record actions are null." name="Given Day 1 RME incremental files are ingested" time="0.001">
    <skipped/>
    <system-out>
  Scenario: Day 1 record are all loaded.           &amp;#27;[90m# se/ff/cc/incremental.feature:11&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33mDay 1 RME incremental files are ingested&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive SCD table&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mthe record count should be correct&amp;#27;[0m

  ## Count of columns should be # + 4 (timestamp, cflag dflag, feeddate) for scd table
  ## verify that timestamps get updated as they want feed date - date that the extract came and date that something actually changed
  ## RME_Incremental_Test_Cases_2nd_Iteration.xlsx
  Background: Full file has been uploaded with action types as null &amp;#27;[90m# se/ff/cc/incremental.feature:8&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Day 1 record actions are null." name="When I query Hive SCD table" time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 1 record actions are null." name="Then all record actions should be null" time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 1 record actions are null." name="Scenario: Day 1 record actions are null." time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 1 record actions are null." name="Scenario: Day 1 record actions are null." time="0.001"/>
  <testcase classname="Scenario: Day 2 records have an action type." name="Given Day 2 RME incremental files are ingested after Day 1 files" time="0">
    <skipped/>
    <system-out>
  Scenario: Day 1 record actions are null.         &amp;#27;[90m# se/ff/cc/incremental.feature:16&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33mDay 1 RME incremental files are ingested&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive SCD table&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mall record actions should be null&amp;#27;[0m

  ## Count of columns should be # + 4 (timestamp, cflag dflag, feeddate) for scd table
  ## verify that timestamps get updated as they want feed date - date that the extract came and date that something actually changed
  ## RME_Incremental_Test_Cases_2nd_Iteration.xlsx
  Background: Full file has been uploaded with action types as null &amp;#27;[90m# se/ff/cc/incremental.feature:8&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Day 2 records have an action type." name="When I query Hive SCD table for the records" time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 2 records have an action type." name="Then all records should have an action" time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 2 records have an action type." name="Scenario: Day 2 records have an action type." time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 2 records have an action type." name="Scenario: Day 2 records have an action type." time="0.001"/>
  <testcase classname="Scenario: Day 2 records are updated in Hue SCD." name="Given Day 2 RME incremental files are ingested after Day 1 files" time="0.001">
    <skipped/>
    <system-out>
  Scenario: Day 2 records have an action type.                       &amp;#27;[90m# se/ff/cc/incremental.feature:21&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33mDay 2 RME incremental files are ingested after Day 1 files&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive SCD table for the records&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mall records should have an action&amp;#27;[0m

  ## Count of columns should be # + 4 (timestamp, cflag dflag, feeddate) for scd table
  ## verify that timestamps get updated as they want feed date - date that the extract came and date that something actually changed
  ## RME_Incremental_Test_Cases_2nd_Iteration.xlsx
  Background: Full file has been uploaded with action types as null &amp;#27;[90m# se/ff/cc/incremental.feature:8&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Day 2 records are updated in Hue SCD." name="When I query Hive SCD table for the records" time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 2 records are updated in Hue SCD." name="Then there should be new records in addition to old records" time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 2 records are updated in Hue SCD." name="Scenario: Day 2 records are updated in Hue SCD." time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 2 records are updated in Hue SCD." name="Scenario: Day 2 records are updated in Hue SCD." time="0.001"/>
  <testcase classname="Scenario: Day 2 records are maybe updated properly in Hue Norm." name="Given Day 2 RME incremental files are ingested after Day 1 files" time="0.008">
    <skipped/>
    <system-out>
  Scenario: Day 2 records are updated in Hue SCD.                    &amp;#27;[90m# se/ff/cc/incremental.feature:26&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33mDay 2 RME incremental files are ingested after Day 1 files&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive SCD table for the records&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mthere should be new records in addition to old records&amp;#27;[0m

  ## Count of columns should be # + 4 (timestamp, cflag dflag, feeddate) for scd table
  ## verify that timestamps get updated as they want feed date - date that the extract came and date that something actually changed
  ## RME_Incremental_Test_Cases_2nd_Iteration.xlsx
  Background: Full file has been uploaded with action types as null &amp;#27;[90m# se/ff/cc/incremental.feature:8&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Day 2 records are maybe updated properly in Hue Norm." name="When I query Hive SCD table for the records" time="0.009">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 2 records are maybe updated properly in Hue Norm." name="Then the record should be updated in Hue Norm table" time="0.009">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 2 records are maybe updated properly in Hue Norm." name="Scenario: Day 2 records are maybe updated properly in Hue Norm." time="0.009">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 2 records are maybe updated properly in Hue Norm." name="Scenario: Day 2 records are maybe updated properly in Hue Norm." time="0.009"/>
  <testcase classname="Scenario: Day 2 records are with dflag should not show up in Hue Norm." name="Given Day 2 RME incremental files are ingested after Day 1 files" time="0">
    <skipped/>
    <system-out>
  Scenario: Day 2 records are maybe updated properly in Hue Norm.    &amp;#27;[90m# se/ff/cc/incremental.feature:31&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33mDay 2 RME incremental files are ingested after Day 1 files&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive SCD table for the records&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mthe record should be updated in Hue Norm table&amp;#27;[0m

  ## Count of columns should be # + 4 (timestamp, cflag dflag, feeddate) for scd table
  ## verify that timestamps get updated as they want feed date - date that the extract came and date that something actually changed
  ## RME_Incremental_Test_Cases_2nd_Iteration.xlsx
  Background: Full file has been uploaded with action types as null &amp;#27;[90m# se/ff/cc/incremental.feature:8&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Day 2 records are with dflag should not show up in Hue Norm." name="When I query Hive SCD table for the records" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 2 records are with dflag should not show up in Hue Norm." name="Then the record should be updated in Hue Norm table" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 2 records are with dflag should not show up in Hue Norm." name="Scenario: Day 2 records are with dflag should not show up in Hue Norm." time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 2 records are with dflag should not show up in Hue Norm." name="Scenario: Day 2 records are with dflag should not show up in Hue Norm." time="0"/>
  <testcase classname="Scenario: Day 3 record count is correct in Hue SCD." name="Given Day 3 RME incremental files are ingested after Day 2 ingestion" time="0.024">
    <skipped/>
    <system-out>
  Scenario: Day 2 records are with dflag should not show up in Hue Norm. &amp;#27;[90m# se/ff/cc/incremental.feature:36&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33mDay 2 RME incremental files are ingested after Day 1 files&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive SCD table for the records&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mthe record should be updated in Hue Norm table&amp;#27;[0m

  ## Count of columns should be # + 4 (timestamp, cflag dflag, feeddate) for scd table
  ## verify that timestamps get updated as they want feed date - date that the extract came and date that something actually changed
  ## RME_Incremental_Test_Cases_2nd_Iteration.xlsx
  Background: Full file has been uploaded with action types as null &amp;#27;[90m# se/ff/cc/incremental.feature:8&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Day 3 record count is correct in Hue SCD." name="When I query Hive SCD table for the records" time="0.024">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 3 record count is correct in Hue SCD." name="Then the record should be updated in Hue Norm table" time="0.024">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 3 record count is correct in Hue SCD." name="Scenario: Day 3 record count is correct in Hue SCD." time="0.024">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 3 record count is correct in Hue SCD." name="Scenario: Day 3 record count is correct in Hue SCD." time="0.024"/>
  <testcase classname="Scenario: Day 3 record count is correct in Hue norm." name="Given Day 3 RME incremental files are ingested after Day 2 ingestion" time="0">
    <skipped/>
    <system-out>
  Scenario: Day 3 record count is correct in Hue SCD.                    &amp;#27;[90m# se/ff/cc/incremental.feature:41&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33mDay 3 RME incremental files are ingested after Day 2 ingestion&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive SCD table for the records&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mthe record should be updated in Hue Norm table&amp;#27;[0m

  ## Count of columns should be # + 4 (timestamp, cflag dflag, feeddate) for scd table
  ## verify that timestamps get updated as they want feed date - date that the extract came and date that something actually changed
  ## RME_Incremental_Test_Cases_2nd_Iteration.xlsx
  Background: Full file has been uploaded with action types as null &amp;#27;[90m# se/ff/cc/incremental.feature:8&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Day 3 record count is correct in Hue norm." name="When I query Hive SCD table for the records" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 3 record count is correct in Hue norm." name="Then the record count should not change in Hue Norm table" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 3 record count is correct in Hue norm." name="Scenario: Day 3 record count is correct in Hue norm." time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 3 record count is correct in Hue norm." name="Scenario: Day 3 record count is correct in Hue norm." time="0.001"/>
  <testcase classname="Scenario: Day 3 records action type is updated." name="Given Day 3 RME incremental files are ingested after Day 2 ingestion" time="0">
    <skipped/>
    <system-out>
  Scenario: Day 3 record count is correct in Hue norm.                   &amp;#27;[90m# se/ff/cc/incremental.feature:46&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33mDay 3 RME incremental files are ingested after Day 2 ingestion&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive SCD table for the records&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mthe record count should not change in Hue Norm table&amp;#27;[0m

  ## Count of columns should be # + 4 (timestamp, cflag dflag, feeddate) for scd table
  ## verify that timestamps get updated as they want feed date - date that the extract came and date that something actually changed
  ## RME_Incremental_Test_Cases_2nd_Iteration.xlsx
  Background: Full file has been uploaded with action types as null &amp;#27;[90m# se/ff/cc/incremental.feature:8&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Day 3 records action type is updated." name="When I query Hive SCD table for the records" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 3 records action type is updated." name="Then the record should have their action type updated" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 3 records action type is updated." name="Scenario: Day 3 records action type is updated." time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 3 records action type is updated." name="Scenario: Day 3 records action type is updated." time="0"/>
  <testcase classname="Scenario: Day 3 records flags are updated correctly." name="Given Day 3 RME incremental files are ingested after Day 2 ingestion" time="0">
    <skipped/>
    <system-out>
  Scenario: Day 3 records action type is updated.                        &amp;#27;[90m# se/ff/cc/incremental.feature:51&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33mDay 3 RME incremental files are ingested after Day 2 ingestion&amp;#27;[0m
    &amp;#27;[33mWhen &amp;#27;[0m&amp;#27;[33mI query Hive SCD table for the records&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mthe record should have their action type updated&amp;#27;[0m

  ## Count of columns should be # + 4 (timestamp, cflag dflag, feeddate) for scd table
  ## verify that timestamps get updated as they want feed date - date that the extract came and date that something actually changed
  ## RME_Incremental_Test_Cases_2nd_Iteration.xlsx
  Background: Full file has been uploaded with action types as null &amp;#27;[90m# se/ff/cc/incremental.feature:8&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Day 3 records flags are updated correctly." name="When I query Hive SCD table for the records" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 3 records flags are updated correctly." name="Then the record should be updated in Hue Norm table" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 3 records flags are updated correctly." name="Scenario: Day 3 records flags are updated correctly." time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Day 3 records flags are updated correctly." name="Scenario: Day 3 records flags are updated correctly." time="0"/>
  <testcase classname="Scenario: A workbook, parsed from an excel spreadsheet, should exist in Cloudera Navigator as metadata." name="Given I have parsed a workbook" time="0"/>
  <testcase classname="Scenario: A workbook, parsed from an excel spreadsheet, should exist in Cloudera Navigator as metadata." name="When I query Cloudera Navigator for that workbook&apos;s metadata" time="0">
    <error message="Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect" type="org.apache.http.conn.HttpHostConnectException">org.apache.http.conn.HttpHostConnectException: Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:159)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
	at ✽.When I query Cloudera Navigator for that workbook&apos;s metadata(se/ff/cc/workbook.feature:9)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:339)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at cucumber.runtime.Utils$1.call(Utils.java:37)
	at cucumber.runtime.Timeout.timeout(Timeout.java:13)
	at cucumber.runtime.Utils.invoke(Utils.java:31)
	at cucumber.runtime.java.JavaStepDefinition.execute(JavaStepDefinition.java:38)
	at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)
	at cucumber.runtime.Runtime.runStep(Runtime.java:299)
	at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)
	at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)
	at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)
	at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:91)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:93)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:37)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.api.junit.Cucumber.run(Cucumber.java:98)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
</error>
    <system-out>com.prft.cif.rest.NavigatorRestClient@dab48d3
2018-11-06 17:40:24 DEBUG RequestAddCookies:123 - CookieSpec selected: default
2018-11-06 17:40:24 DEBUG RequestAuthCache:77 - Auth cache not set in the context
2018-11-06 17:40:24 DEBUG PoolingHttpClientConnectionManager:265 - Connection request: [route: {s}-&gt;https://bclmp01vr.bcbsma.com:7187][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
2018-11-06 17:40:24 DEBUG PoolingHttpClientConnectionManager:309 - Connection leased: [id: 3][route: {s}-&gt;https://bclmp01vr.bcbsma.com:7187][total kept alive: 0; route allocated: 1 of 2; total allocated: 1 of 20]
2018-11-06 17:40:24 DEBUG MainClientExec:235 - Opening connection {s}-&gt;https://bclmp01vr.bcbsma.com:7187
2018-11-06 17:40:24 DEBUG DefaultHttpClientConnectionOperator:139 - Connecting to bclmp01vr.bcbsma.com/10.15.126.18:7187
2018-11-06 17:40:24 DEBUG SSLConnectionSocketFactory:337 - Connecting socket to bclmp01vr.bcbsma.com/10.15.126.18:7187 with timeout 0
2018-11-06 17:40:45 DEBUG DefaultManagedHttpClientConnection:96 - http-outgoing-3: Shutdown connection
2018-11-06 17:40:45 DEBUG MainClientExec:129 - Connection discarded
2018-11-06 17:40:45 DEBUG PoolingHttpClientConnectionManager:348 - Connection released: [id: 3][route: {s}-&gt;https://bclmp01vr.bcbsma.com:7187][total kept alive: 0; route allocated: 0 of 2; total allocated: 0 of 20]
</system-out>
  </testcase>
  <testcase classname="Scenario: A workbook, parsed from an excel spreadsheet, should exist in Cloudera Navigator as metadata." name="Scenario: A workbook, parsed from an excel spreadsheet, should exist in Cloudera Navigator as metadata." time="0.015">
    <error message="Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect" type="org.apache.http.conn.HttpHostConnectException">org.apache.http.conn.HttpHostConnectException: Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:159)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
	at ✽.When I query Cloudera Navigator for that workbook&apos;s metadata(se/ff/cc/workbook.feature:9)
Caused by: java.net.ConnectException: Connection timed out: connect
	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
	at java.net.Socket.connect(Socket.java:589)
	at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:339)
	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at cucumber.runtime.Utils$1.call(Utils.java:37)
	at cucumber.runtime.Timeout.timeout(Timeout.java:13)
	at cucumber.runtime.Utils.invoke(Utils.java:31)
	at cucumber.runtime.java.JavaStepDefinition.execute(JavaStepDefinition.java:38)
	at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)
	at cucumber.runtime.Runtime.runStep(Runtime.java:299)
	at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)
	at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)
	at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)
	at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:91)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)
	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:93)
	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:37)
	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
	at cucumber.api.junit.Cucumber.run(Cucumber.java:98)
	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
	at java.lang.reflect.Method.invoke(Method.java:498)
	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
</error>
  </testcase>
  <testcase classname="Scenario: A workbook, parsed from an excel spreadsheet, should exist in Cloudera Navigator as metadata." name="Then it should match the parsed workbook" time="0.015">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Curate data set db creation." name="Given I have parsed a curate workbook" time="0.004">
    <skipped/>
    <system-out>
  Scenario: A workbook, parsed from an excel spreadsheet, should exist in Cloudera Navigator as metadata. &amp;#27;[90m# se/ff/cc/workbook.feature:7&amp;#27;[0m
    &amp;#27;[32mGiven &amp;#27;[0m&amp;#27;[32mI have parsed a workbook&amp;#27;[0m                                                                        &amp;#27;[90m# WorkbookStepDefs.some_start_condition()&amp;#27;[0m
    &amp;#27;[31mWhen &amp;#27;[0m&amp;#27;[31mI query Cloudera Navigator for that workbook&apos;s metadata&amp;#27;[0m                                          &amp;#27;[90m# WorkbookStepDefs.something_is_done()&amp;#27;[0m
      &amp;#27;[31morg.apache.http.conn.HttpHostConnectException: Connect to bclmp01vr.bcbsma.com:7187 [bclmp01vr.bcbsma.com/10.15.126.18] failed: Connection timed out: connect
      	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:159)
      	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
      	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
      	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
      	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
      	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
      	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
      	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
      	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
      	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
      	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
      	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
      	at ?.When I query Cloudera Navigator for that workbook&apos;s metadata(se/ff/cc/workbook.feature:9)
      Caused by: java.net.ConnectException: Connection timed out: connect
      	at java.net.DualStackPlainSocketImpl.connect0(Native Method)
      	at java.net.DualStackPlainSocketImpl.socketConnect(DualStackPlainSocketImpl.java:79)
      	at java.net.AbstractPlainSocketImpl.doConnect(AbstractPlainSocketImpl.java:350)
      	at java.net.AbstractPlainSocketImpl.connectToAddress(AbstractPlainSocketImpl.java:206)
      	at java.net.AbstractPlainSocketImpl.connect(AbstractPlainSocketImpl.java:188)
      	at java.net.PlainSocketImpl.connect(PlainSocketImpl.java:172)
      	at java.net.SocksSocketImpl.connect(SocksSocketImpl.java:392)
      	at java.net.Socket.connect(Socket.java:589)
      	at org.apache.http.conn.ssl.SSLConnectionSocketFactory.connectSocket(SSLConnectionSocketFactory.java:339)
      	at org.apache.http.impl.conn.DefaultHttpClientConnectionOperator.connect(DefaultHttpClientConnectionOperator.java:142)
      	at org.apache.http.impl.conn.PoolingHttpClientConnectionManager.connect(PoolingHttpClientConnectionManager.java:373)
      	at org.apache.http.impl.execchain.MainClientExec.establishRoute(MainClientExec.java:381)
      	at org.apache.http.impl.execchain.MainClientExec.execute(MainClientExec.java:237)
      	at org.apache.http.impl.execchain.ProtocolExec.execute(ProtocolExec.java:185)
      	at org.apache.http.impl.execchain.RetryExec.execute(RetryExec.java:89)
      	at org.apache.http.impl.execchain.RedirectExec.execute(RedirectExec.java:111)
      	at org.apache.http.impl.client.InternalHttpClient.doExecute(InternalHttpClient.java:185)
      	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:83)
      	at org.apache.http.impl.client.CloseableHttpClient.execute(CloseableHttpClient.java:108)
      	at com.prft.cif.rest.CIFRestClient.get(CIFRestClient.java:155)
      	at se.ff.cc.WorkbookStepDefs.something_is_done(WorkbookStepDefs.java:60)
      	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
      	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
      	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
      	at java.lang.reflect.Method.invoke(Method.java:498)
      	at cucumber.runtime.Utils$1.call(Utils.java:37)
      	at cucumber.runtime.Timeout.timeout(Timeout.java:13)
      	at cucumber.runtime.Utils.invoke(Utils.java:31)
      	at cucumber.runtime.java.JavaStepDefinition.execute(JavaStepDefinition.java:38)
      	at cucumber.runtime.StepDefinitionMatch.runStep(StepDefinitionMatch.java:37)
      	at cucumber.runtime.Runtime.runStep(Runtime.java:299)
      	at cucumber.runtime.model.StepContainer.runStep(StepContainer.java:44)
      	at cucumber.runtime.model.StepContainer.runSteps(StepContainer.java:39)
      	at cucumber.runtime.model.CucumberScenario.run(CucumberScenario.java:44)
      	at cucumber.runtime.junit.ExecutionUnitRunner.run(ExecutionUnitRunner.java:91)
      	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:63)
      	at cucumber.runtime.junit.FeatureRunner.runChild(FeatureRunner.java:18)
      	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
      	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
      	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
      	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
      	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
      	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
      	at cucumber.runtime.junit.FeatureRunner.run(FeatureRunner.java:70)
      	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:93)
      	at cucumber.api.junit.Cucumber.runChild(Cucumber.java:37)
      	at org.junit.runners.ParentRunner$3.run(ParentRunner.java:290)
      	at org.junit.runners.ParentRunner$1.schedule(ParentRunner.java:71)
      	at org.junit.runners.ParentRunner.runChildren(ParentRunner.java:288)
      	at org.junit.runners.ParentRunner.access$000(ParentRunner.java:58)
      	at org.junit.runners.ParentRunner$2.evaluate(ParentRunner.java:268)
      	at org.junit.runners.ParentRunner.run(ParentRunner.java:363)
      	at cucumber.api.junit.Cucumber.run(Cucumber.java:98)
      	at org.apache.maven.surefire.junit4.JUnit4Provider.execute(JUnit4Provider.java:252)
      	at org.apache.maven.surefire.junit4.JUnit4Provider.executeTestSet(JUnit4Provider.java:141)
      	at org.apache.maven.surefire.junit4.JUnit4Provider.invoke(JUnit4Provider.java:112)
      	at sun.reflect.NativeMethodAccessorImpl.invoke0(Native Method)
      	at sun.reflect.NativeMethodAccessorImpl.invoke(NativeMethodAccessorImpl.java:62)
      	at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43)
      	at java.lang.reflect.Method.invoke(Method.java:498)
      	at org.apache.maven.surefire.util.ReflectionUtils.invokeMethodWithArray(ReflectionUtils.java:189)
      	at org.apache.maven.surefire.booter.ProviderFactory$ProviderProxy.invoke(ProviderFactory.java:165)
      	at org.apache.maven.surefire.booter.ProviderFactory.invokeProvider(ProviderFactory.java:85)
      	at org.apache.maven.surefire.booter.ForkedBooter.runSuitesInProcess(ForkedBooter.java:115)
      	at org.apache.maven.surefire.booter.ForkedBooter.main(ForkedBooter.java:75)
      &amp;#27;[0m
    &amp;#27;[36mThen &amp;#27;[0m&amp;#27;[36mit should match the parsed workbook&amp;#27;[0m                                                              &amp;#27;[90m# WorkbookStepDefs.something_should_happen()&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Curate data set db creation." name="When I query Cloudera Navigator for that workbook&apos;s metadata" time="0.004">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Curate data set db creation." name="Then I should see Hive DB created with appropriate name" time="0.004">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Curate data set db creation." name="Scenario: Curate data set db creation." time="0.004">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Curate data set db creation." name="Scenario: Curate data set db creation." time="0.004"/>
  <testcase classname="Scenario: Publish workbook schema validation." name="Given I have parsed a publish workbook" time="0">
    <skipped/>
    <system-out>
  ##Just check that a database exists with the right name
  Scenario: Curate data set db creation.                         &amp;#27;[90m# se/ff/cc/workbook.feature:13&amp;#27;[0m
    &amp;#27;[33mGiven &amp;#27;[0m&amp;#27;[33mI have parsed a curate workbook&amp;#27;[0m
    &amp;#27;[36mWhen &amp;#27;[0m&amp;#27;[36mI query Cloudera Navigator for that workbook&apos;s metadata&amp;#27;[0m &amp;#27;[90m# WorkbookStepDefs.something_is_done()&amp;#27;[0m
    &amp;#27;[33mThen &amp;#27;[0m&amp;#27;[33mI should see Hive DB created with appropriate name&amp;#27;[0m
</system-out>
  </testcase>
  <testcase classname="Scenario: Publish workbook schema validation." name="When I query Cloudera Navigator for that workbook&apos;s metadata" time="0">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Publish workbook schema validation." name="Then I should see appropriate Hive columns in the appropriate DB" time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Publish workbook schema validation." name="Scenario: Publish workbook schema validation." time="0.001">
    <skipped/>
  </testcase>
  <testcase classname="Scenario: Publish workbook schema validation." name="Scenario: Publish workbook schema validation." time="0.001"/>
</testsuite>